{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e562103",
   "metadata": {},
   "source": [
    "# Merge PIO predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54615089",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from collections import Counter\n",
    "import random\n",
    "from sklearn.metrics import (accuracy_score, classification_report,\n",
    "                             confusion_matrix, f1_score, \n",
    "                             precision_score, recall_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2d0aee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = '/mnt/nas2/results/Results/systematicReview/SemEval2023/predictions_test/without_Dropout/'\n",
    "\n",
    "entities = ['participant', 'intervention', 'outcome']\n",
    "seeds = ['0', '1', '42']\n",
    "embedding = ['roberta', 'biomedroberta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eed68a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_cols(df):\n",
    "    print( df.columns )\n",
    "    df.rename(columns={df.columns[0]: 'post_id'},inplace=True)\n",
    "    df.rename(columns={df.columns[1]: 'subredit_id'},inplace=True)\n",
    "    df.rename(columns={df.columns[2]: 'words'},inplace=True)\n",
    "    df.rename(columns={df.columns[3]: 'labels'},inplace=True)\n",
    "    \n",
    "    \n",
    "    columns_titles = [\"subredit_id\",\"post_id\"]\n",
    "    df=df.reindex(columns=columns_titles)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9ffe300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(picos, embed):\n",
    "    \n",
    "    file_paths = []\n",
    "\n",
    "    s1 = dict()\n",
    "    s2 = dict()\n",
    "    s3 = dict()\n",
    "\n",
    "    for i in seeds:\n",
    "\n",
    "        dir_path = os.path.join(base, picos, i, embed)\n",
    "        files = os.listdir(dir_path)\n",
    "\n",
    "        for f in files:\n",
    "            file_path = os.path.join(base, picos, i, embed, f)\n",
    "            file_paths.append(file_path)    \n",
    "            # get the file into a dataframe\n",
    "            df = pd.read_csv(file_path, sep=',')\n",
    "            col = df.columns[0]\n",
    "            #df = rename_cols(df) \n",
    "            key = f.split('_')[0].replace('ensemble', '')\n",
    "            if i == '0':\n",
    "                s1[ key ] = df\n",
    "            if i == '1':\n",
    "                s2[ key ] = df\n",
    "            if i == '42':\n",
    "                s3[ key ] = df\n",
    "                \n",
    "    return s1, s2, s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea87e680",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1, p2, p3 = get_predictions(entities[0], embedding[0])\n",
    "i1, i2, i3 = get_predictions(entities[1], embedding[0])\n",
    "o1, o2, o3 = get_predictions(entities[2], embedding[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a704039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 14 14\n",
      "14 14 14\n",
      "14 14 14\n"
     ]
    }
   ],
   "source": [
    "print( len(p1), len(p2), len(p3) )\n",
    "print( len(i1), len(i2), len(i3) )\n",
    "print( len(o1), len(o2), len(o3) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "377f053c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ensembles(d1, d2, d3, ensembles):\n",
    "    \n",
    "    en1, en2, en3 = ensembles\n",
    "    \n",
    "    x = d1[str(en1)]['labels']\n",
    "    y = d2[str(en2)]['labels']\n",
    "    z = d3[str(en3)]['labels']\n",
    "    \n",
    "    return x,y,z\n",
    "\n",
    "p1l, p2l, p3l = get_ensembles(p1, p2, p3, ensembles = [14, 14, 14])\n",
    "i1l, i2l, i3l = get_ensembles(i1, i2, i3, ensembles = [14, 14, 14])\n",
    "o1l, o2l, o3l = get_ensembles(o1, o2, o3, ensembles = [14, 14, 14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a30ce3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_choice(inp):\n",
    "    \n",
    "    return entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6e9ed98",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "randomness involved in:  3135\n",
      "randomness NOT involved in:  2536\n"
     ]
    }
   ],
   "source": [
    "def merge_preds(p_s, i_s, o_s):\n",
    "    \n",
    "    count_random = 0\n",
    "    count_not_random = 0\n",
    "\n",
    "    merged = []\n",
    "    \n",
    "    p1labs, p2labs, p3labs = p_s\n",
    "    i1labs, i2labs, i3labs = i_s\n",
    "    o1labs, o2labs, o3labs = o_s\n",
    "    \n",
    "    for counter, (p_1, p_2, p_3, i_1, i_2, i_3, o_1, o_2, o_3) in enumerate( zip( p1labs, p2labs, p3labs, i1labs, i2labs, i3labs, o1labs, o2labs, o3labs ) ):\n",
    "        \n",
    "        all_labels = [p_1, p_2, p_3, i_1, i_2, i_3, o_1, o_2, o_3]\n",
    "        \n",
    "        if len( set( all_labels ) ) == 1:\n",
    "            merged.append( 'O' )\n",
    "        else:\n",
    "            filtered_o = list(filter(('O').__ne__, all_labels))\n",
    "            \n",
    "            if len( set( filtered_o ) ) == 1:\n",
    "                #print( filtered_o, ' ------ ', set( filtered_o ) )\n",
    "                entity_label = list( set( filtered_o ) )[0]\n",
    "                merged.append( entity_label )\n",
    "                count_not_random = count_not_random + 1\n",
    "            else:\n",
    "                c_p = filtered_o.count('POP')\n",
    "                c_i = filtered_o.count('INT')\n",
    "                c_o = filtered_o.count('OUT')\n",
    "                counter_dict = Counter(filtered_o)\n",
    "                counter_reverse = dict((v, k) for k, v in counter_dict.items())\n",
    "                \n",
    "                if (c_p == c_i == c_o) or len( set(counter_dict.values()) ) == 1:\n",
    "                    entity_label = random.sample(filtered_o, 1)\n",
    "                    entity_label = entity_label[0]\n",
    "                    merged.append( entity_label )\n",
    "                    count_random = count_random + 1\n",
    "                else:\n",
    "                    first_two = dict( counter_dict.most_common( 2 ) )\n",
    "\n",
    "                    if len(set( first_two.values() )) > 1:\n",
    "                        entity_label = dict(counter_dict.most_common( 1 ))\n",
    "                        entity_label = list(entity_label.keys())[0]\n",
    "                        merged.append( entity_label )\n",
    "                        #print( counter_dict , ' ----- ',  entity_label)\n",
    "                        count_not_random = count_not_random + 1\n",
    "                    else:\n",
    "                        \n",
    "                        entity_label = random.sample(list( first_two.keys() ), 1)\n",
    "                        entity_label = entity_label[0]\n",
    "                        merged.append( entity_label )\n",
    "                        #print( counter_dict , ' ----- ',  entity_label)\n",
    "                        count_random = count_random + 1\n",
    "\n",
    "        \n",
    "        #if counter == 900:\n",
    "        #    break\n",
    "    \n",
    "    print( 'randomness involved in: ', count_random )\n",
    "    print( 'randomness NOT involved in: ', count_not_random )\n",
    "    \n",
    "    return merged\n",
    "\n",
    "\n",
    "predictions_merged = merge_preds(p_s = [p1l, p2l, p3l], i_s = [i1l, i2l, i3l], o_s = [o1l, o2l, o3l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5be31f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_preds(df, ensemb, l):\n",
    "    \n",
    "    base_path = f\"/mnt/nas2/results/Results/systematicReview/SemEval2023/submission/random/{ensemb}.csv\"\n",
    "    df = df['14']\n",
    "    df = df.assign(labels = pd.Series(l).values)\n",
    "    \n",
    "    df.to_csv(base_path, encoding='utf-8')\n",
    "    \n",
    "write_preds(p1, '14', predictions_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec4be0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72dcebd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
